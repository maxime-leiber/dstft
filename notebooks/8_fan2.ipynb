{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxime/mambaforge/envs/env/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from dstft.loss import entropy_loss, kurtosis_loss, kurtosis2_loss\n",
    "from dstft import DSTFT, FDSTFT\n",
    "from dstft import frequency_tracking\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sr = librosa.load('../../../data/raw/fan/7.wav', sr=2_000)\n",
    "vitesse = {}\n",
    "Audio(signal, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(signal).float().to(device)[None, 22_000:52_000] \n",
    "print(sr, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = FDSTFT(x, win_length=1_500, support=1_500, stride=100, win_requires_grad=False, stride_requires_grad=False, win_p=None, stride_p=None)\n",
    "spec, *_ = dstft(x)\n",
    "vitesse['1500'] = spec.cpu() \n",
    "dstft.print(spec, weights=False, wins=False, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = FDSTFT(x, win_length=300, support=1_000, stride=100, win_requires_grad=False, stride_requires_grad=False, win_p=None, stride_p=None)\n",
    "spec, stft, real, imag, phase = dstft(x)\n",
    "vitesse['300'] = spec.cpu() \n",
    "dstft.print(spec, weights=False, wins=False, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = FDSTFT(x, win_length=500, support=1_000, stride=100, win_requires_grad=False, stride_requires_grad=False, win_p=None, stride_p=None)\n",
    "spec, stft, real, imag, phase = dstft(x)\n",
    "vitesse['500'] = spec.cpu() \n",
    "dstft.print(spec, weights=False, wins=False, bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single window length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dstft.tap_win.shape, dstft.strided_x.shape, dstft.tapered_x.shape)\n",
    "#plt.plot(dstft.tap_win[0, 0].cpu())\n",
    "#plt.plot(dstft.strided_x[0, 0].cpu())\n",
    "#plt.plot(dstft.tapered_x[0, 0].cpu())\n",
    "\n",
    "aa = dstft.tapered_x\n",
    "\n",
    "cc = aa.clone()\n",
    "cc[ cc.abs() < .001 * aa.mean() ] = aa.mean()\n",
    "\n",
    "bb = aa[0, 0]\n",
    "dd = cc[0, 0]\n",
    "for i in range(2):\n",
    "    bb = torch.cat((bb, aa[0, i+1]), 0)\n",
    "    dd = torch.cat((dd, cc[0, i+1]), 0)\n",
    "\n",
    "\n",
    "plt.plot(bb.cpu())\n",
    "#plt.figure()\n",
    "plt.plot(dd.cpu())\n",
    "print(dd.mean(), bb.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "min_err = 100\n",
    "min_win = 0\n",
    "\n",
    "for win_length in range(100, 2_000, 1):\n",
    "    dstft = FDSTFT(x, win_length=win_length, support=2_000, stride=100, win_requires_grad=False, stride_requires_grad=False, win_p=None, stride_p=None)\n",
    "    spec, *_ = dstft(x)\n",
    "    \n",
    "    aa = dstft.tapered_x\n",
    "    aa[ aa.abs() < .01 * aa.mean() ] = aa.mean()\n",
    "    fig, ax = plt.subplot(1, 2)\n",
    "    ax[0].plot(dstft.tapered_x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    err = aa.var() #1_000 / kurtosis2_loss(spec).mean() #entropy_loss(spec)\n",
    "    \n",
    "    \n",
    "    if err < min_err:\n",
    "        min_err = err\n",
    "        min_win = win_length\n",
    "    losses.append(err.cpu())\n",
    "    \n",
    "print(min_win, min_err)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(100, 2_000, 1), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = FDSTFT(x, win_length=577, support=2_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p=None, stride_p=None)\n",
    "params = [{'params': dstft.win_length,    'lr': 100.0}, ] \n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=99, verbose=True)\n",
    "\n",
    "min_err = 100\n",
    "min_win = 0\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()    \n",
    "    spec, *_ = dstft(x)\n",
    "    err = entropy_loss(spec)\n",
    "    err.backward()    \n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if err < min_err:\n",
    "        min_err = err\n",
    "        min_win = dstft.win_length.item()\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "\n",
    "vitesse['single'] = spec.cpu() \n",
    "print(epoch)\n",
    "print(min_win, min_err)\n",
    "dstft.print(spec, x, bar=True, wins=False, weights=False)\n",
    "print(f'{dstft.win_length.item():.1f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-varying window length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = FDSTFT(x, win_length=1577, support=2_000, stride=50, win_requires_grad=True, stride_requires_grad=False, win_p='t', win_min=100)\n",
    "params = [{'params': dstft.win_length, 'lr': 100.0}, ] \n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()    \n",
    "    spec, *_ = dstft(x)\n",
    "    err = dstft.tapered_x.var() #entropy_loss(spec)\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "print(epoch)\n",
    "dstft.print(spec, x, bar=True, wins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = FDSTFT(x, win_length=577, support=1_000, stride=50, win_requires_grad=True, stride_requires_grad=False, win_p='t', win_min=100)\n",
    "params = [{'params': dstft.win_length, 'lr': 100.0}, ] \n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()    \n",
    "    spec, *_ = dstft(x)\n",
    "    err = dstft.tapered_x.var() + 0.003 * (dstft.actual_win_length.diff(dim=1).pow(2) + torch.finfo(x.dtype).eps).sqrt().mean() # entropy_loss(spec) \n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "vitesse['time-varying'] = spec.cpu() \n",
    "print(epoch)\n",
    "dstft.print(spec, x, bar=True, wins=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency-varying window length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = DSTFT(x, win_length=577, support=1_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p='f', win_min=100)\n",
    "params = [{'params': dstft.win_length,    'lr': 100.0}, ] \n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()\n",
    "    spec, *_ = dstft(x)\n",
    "    err = entropy_loss(spec)\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "print(epoch)\n",
    "dstft.print(spec, x, wins=False, bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = DSTFT(x, win_length=577, support=1_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p='f', win_min=100)\n",
    "params = [{'params': dstft.win_length, 'lr': 100.0},  ]\n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()\n",
    "    spec, *_ = dstft(x)\n",
    "    err = entropy_loss(spec) + 0.005 * (dstft.actual_win_length.diff(dim=0).pow(2) + torch.finfo(x.dtype).eps).sqrt().mean()\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "print(epoch)\n",
    "dstft.print(spec, x, wins=False, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DSTFT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dstft \u001b[39m=\u001b[39m DSTFT(x, win_length\u001b[39m=\u001b[39m\u001b[39m577\u001b[39m, support\u001b[39m=\u001b[39m\u001b[39m1_000\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, win_requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, stride_requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, win_p\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m, win_min\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      2\u001b[0m params \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: dstft\u001b[39m.\u001b[39mwin_length, \u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m100.0\u001b[39m},  ]\n\u001b[1;32m      3\u001b[0m opt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DSTFT' is not defined"
     ]
    }
   ],
   "source": [
    "dstft = DSTFT(x, win_length=577, support=1_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p='f', win_min=100)\n",
    "params = [{'params': dstft.win_length, 'lr': 100.0},  ]\n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()\n",
    "    spec, *_ = dstft(x)\n",
    "    err = entropy_loss(spec) + 0.01 * (dstft.actual_win_length.diff(dim=0).pow(2) + torch.finfo(x.dtype).eps).sqrt().mean()\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "print(epoch)\n",
    "dstft.print(spec, x, wins=False, bar=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-and-frequency-varying window length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = DSTFT(x, win_length=577, support=1_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p='tf', win_min=100)\n",
    "params = [{'params': dstft.win_length, 'lr': 100.0},  ] \n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()\n",
    "    spec, *_ = dstft(x)\n",
    "    err = entropy_loss(spec)  #entropy_loss(spec)\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "print(epoch)\n",
    "dstft.print(spec, x, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstft = DSTFT(x, win_length=577, support=1_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p='tf', win_min=100)\n",
    "params = [{'params': dstft.win_length,'lr': 100.0}, {'params': dstft.strides,    'lr': 1.0}] \n",
    "opt = torch.optim.Adam(params)\n",
    "sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "for epoch in range(1_000):\n",
    "    opt.zero_grad()\n",
    "    spec, *_ = dstft(x)\n",
    "    err = entropy_loss(spec) + 0.01 * (dstft.actual_win_length.diff(dim=0)[:, :-1].pow(2) + dstft.actual_win_length.diff(dim=1)[:-1].pow(2) + torch.finfo(x.dtype).eps).sqrt().mean()\n",
    "    err.backward()\n",
    "    opt.step()\n",
    "    sch.step(err)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 1:\n",
    "        break\n",
    "    \n",
    "print(epoch)\n",
    "dstft.print(spec, x, bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = torch.split(x[0], 22_000)\n",
    "spec_all = []\n",
    "weight_all = []\n",
    "\n",
    "for i, x_tmp in enumerate(chunks):    \n",
    "    x_tmp = x_tmp[None, ...]    \n",
    "    \n",
    "    dstft = DSTFT(x_tmp, win_length=577, support=1_000, stride=100, win_requires_grad=True, stride_requires_grad=False, win_p='tf', win_min=100)\n",
    "    params = [{'params': dstft.win_length, 'lr': 100.0},  ] \n",
    "    opt = torch.optim.Adam(params)\n",
    "    sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt, mode='min', factor=.1, patience=9, verbose=True)\n",
    "\n",
    "    for epoch in range(1_000):\n",
    "        opt.zero_grad()\n",
    "        spec, *_ = dstft(x_tmp)\n",
    "        err = entropy_loss(spec)\n",
    "        err.backward()\n",
    "        opt.step()\n",
    "        sch.step(err)\n",
    "        \n",
    "        if opt.param_groups[0]['lr'] < 1:\n",
    "            break\n",
    "        \n",
    "    print(i, x_tmp.shape, epoch)\n",
    "    #dstft.print(spec, x_tmp, bar=True, wins=False)\n",
    "    \n",
    "    #print(spec.shape, dstft.actual_win_length[:dstft.F].detach().shape)\n",
    "    spec_all.append(spec)\n",
    "    weight_all.append(dstft.actual_win_length[:dstft.F].detach())\n",
    "    \n",
    "\n",
    "\n",
    "specs = spec_all[0]\n",
    "#print(specs.shape, specs.dtype)\n",
    "weights = weight_all[0]\n",
    "size = len(spec_all)-1 \n",
    "for i in range(size):\n",
    "    specs = torch.cat((specs, spec_all[i+1]), dim=2)\n",
    "    weights = torch.cat((weights, weight_all[i+1]), dim=1)\n",
    "\n",
    "#print(specs.shape, weights.shape)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Spectrogram')\n",
    "ax = plt.subplot()\n",
    "im = ax.imshow(specs[0].detach().cpu().log(), aspect='auto', origin='lower', cmap='jet', extent=[0,specs.shape[-1], 0, specs.shape[-2]])\n",
    "plt.ylabel('frequencies')\n",
    "plt.xlabel('frames')\n",
    "plt.colorbar(im, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Distribution of window lengths')\n",
    "ax = plt.subplot()\n",
    "im = ax.imshow(weights.detach().cpu(), aspect='auto', origin='lower', cmap='jet')\n",
    "ax.set_ylabel('frequencies')\n",
    "ax.set_xlabel('frames')\n",
    "plt.colorbar(im, ax=ax)\n",
    "im.set_clim(dstft.win_min, dstft.win_max)   \n",
    "plt.show()   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec = torch.fft.rfft(x).abs().log()\n",
    "#print(spec.shape)\n",
    "#plt.plot(spec[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "for key, spec in vitesse.items():\n",
    "    spec = spec[0]\n",
    "    f_hat, out = frequency_tracking(y=x, fs=1, spec=spec, fmin=0, fmax=.25, alpha=100, orders=[2, 4, 6, 8, 10])\n",
    "    freq[key] = out\n",
    "    plt.figure()\n",
    "    plt.title(f'Spectrogram {key}')\n",
    "    ax = plt.subplot()\n",
    "    im = ax.imshow(spec.detach().cpu().log(), aspect='auto', origin='lower', cmap='jet', extent=[0,spec.shape[-1], 0, spec.shape[-2]])\n",
    "    plt.ylabel('frequencies')\n",
    "    plt.xlabel('frames')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.plot(out, '--k', linewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, f in freq.items():\n",
    "    plt.plot(f, label=key)\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
